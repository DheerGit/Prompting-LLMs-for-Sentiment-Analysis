{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f3061fa0-a708-4bb1-8be0-fe9927264274",
      "metadata": {
        "id": "f3061fa0-a708-4bb1-8be0-fe9927264274"
      },
      "source": [
        "# Applications of Large Language Models\n",
        "**Dataset Used**: IMDB Movie Reviews\n",
        "    \n",
        "**Models used**:\n",
        "    \n",
        "    Claude 3 Sonnet : https://www.anthropic.com/news/claude-3-5-sonnet\n",
        "    Llama-3-70B-instruct-v1 : https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct\n",
        "    \n",
        "**Instance** : g4dn.xlarge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639c2daf-75e7-4fa1-83f2-74cf6601fba8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:50.043456Z",
          "iopub.status.busy": "2025-02-24T21:09:50.043088Z",
          "iopub.status.idle": "2025-02-24T21:09:50.047049Z",
          "shell.execute_reply": "2025-02-24T21:09:50.046518Z",
          "shell.execute_reply.started": "2025-02-24T21:09:50.043427Z"
        },
        "id": "639c2daf-75e7-4fa1-83f2-74cf6601fba8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "import json\n",
        "random.seed(42) # set the seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eede25b4-8d01-4d7d-b37a-1365c5b90462",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:50.047951Z",
          "iopub.status.busy": "2025-02-24T21:09:50.047676Z",
          "iopub.status.idle": "2025-02-24T21:09:52.407908Z",
          "shell.execute_reply": "2025-02-24T21:09:52.407374Z",
          "shell.execute_reply.started": "2025-02-24T21:09:50.047931Z"
        },
        "id": "eede25b4-8d01-4d7d-b37a-1365c5b90462",
        "outputId": "45eef264-a727-412c-ef52-1a57abad018f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# importing the dataset\n",
        "import s3fs\n",
        "fs=s3fs.S3FileSystem(anon=False) # initialize the file system\n",
        "s3_url='s3://amazon-sagemaker-058264306111-us-east-1-e23504aef6c5/dzd_5l5kah6gnsnq3r/bzbm82rtfbxpgn/dev/IMDB Dataset.csv' # location of the file in s3 bucket\n",
        "data=pd.read_csv(s3_url)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abca086-e625-4809-a836-8579ca0386d2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:52.409276Z",
          "iopub.status.busy": "2025-02-24T21:09:52.409010Z",
          "iopub.status.idle": "2025-02-24T21:09:52.415248Z",
          "shell.execute_reply": "2025-02-24T21:09:52.414764Z",
          "shell.execute_reply.started": "2025-02-24T21:09:52.409256Z"
        },
        "id": "1abca086-e625-4809-a836-8579ca0386d2"
      },
      "outputs": [],
      "source": [
        "# Creating a bedrock runtime client.\n",
        "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
        "# each model has a unique Model Identifier\n",
        "model_id='anthropic.claude-3-sonnet-20240229-v1:0' # no of tokens for input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f55f6df-0210-4798-aba3-0753e3548fa1",
      "metadata": {
        "id": "0f55f6df-0210-4798-aba3-0753e3548fa1"
      },
      "source": [
        "## Zero-shot prompting\n",
        "\n",
        "Zero-shot prompting is a technique in natural language processing (NLP) where a language model is asked to perform a task without any prior examples or training specific to that task. Instead, the model relies on its pre-trained knowledge to generate responses based on the prompt alone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2e6886-8490-4d5d-93e2-cbf470a3c57e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:52.417966Z",
          "iopub.status.busy": "2025-02-24T21:09:52.417579Z",
          "iopub.status.idle": "2025-02-24T21:09:52.421482Z",
          "shell.execute_reply": "2025-02-24T21:09:52.421010Z",
          "shell.execute_reply.started": "2025-02-24T21:09:52.417946Z"
        },
        "id": "4f2e6886-8490-4d5d-93e2-cbf470a3c57e",
        "outputId": "ca0d4918-371d-48a6-c593-2f94ced457d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Water shows the plight of Indian widows in the late 1930s, says in the end that the problem still exists largely by giving statistics in the end, refers to Gandhi several times in the movie before finally having a scene depicting him and does nothing extra ordinarily innovative or new in the movie. Yes, the cinematography is pretty impressive but that cannot be the soul of any movie for me. <br /><br />India has had several problems like many other nations but it has got rid of many of these problems at large. What if a movie is made on racism in America in a particular year which ends with 'x number of Americans still experience racism today'. <br /><br />a) How would it be relevant, and, b) How would it be some thing so extra ordinary being depicted in cinema.<br /><br />A view I read from a Deepa Mehta interview was that this movie is being interpreted as a voice for the marginalised every where. From reviews I read every where, the common thing I am hearing is how the director did a great job and was brave in bringing a problem to the world. The movie is more about a specific problem a society faced (and has got rid of through reforms at large). <br /><br />I do not see any thing earth shattering about the movie. Moreover, the movie lacked soul and shifted between the plots of Chuiyya and Kalyani. Sarala, the young Sri Lankan actress, portrayed the role of Chuiyya superbly and that was the only thing which impressed me about the movie, sadly.\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "# import a data sample from the dataset and prompt the model to perform sentiment analysis.\n",
        "random_index=random.randint(0,50000) # create a random index\n",
        "data_sample=data.iloc[random_index]# access a random sample from the dataset using random_index\n",
        "print(data_sample['review'])\n",
        "print(data_sample['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd83959c-f554-46ca-88c8-e6333c488a56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:52.422342Z",
          "iopub.status.busy": "2025-02-24T21:09:52.422117Z",
          "iopub.status.idle": "2025-02-24T21:09:52.426685Z",
          "shell.execute_reply": "2025-02-24T21:09:52.426195Z",
          "shell.execute_reply.started": "2025-02-24T21:09:52.422324Z"
        },
        "id": "dd83959c-f554-46ca-88c8-e6333c488a56"
      },
      "outputs": [],
      "source": [
        "# now prompt the model\n",
        "# Extracting Data from the Dataset\n",
        "review=data_sample['review']\n",
        "sentiment=data_sample['sentiment']\n",
        "# Defines a formatted string (f-string) that instructs the model to classify the sentiment.\n",
        "prompt=f''' You are a highly accurate sentiment analysis model trained to classify movie reviews. Your task is to analyze the sentiment of the given review and categorize it as one of the following labels:\n",
        "\n",
        "Positive: The review expresses a favorable opinion about the movie.\n",
        "Negative: The review expresses an unfavorable opinion about the movie.\n",
        "\n",
        "Expected Output Format:\n",
        "positive/negative\n",
        "\n",
        "Provide only the sentiment label in one word without any additional explanation.\n",
        "            {review}\n",
        "        '''\n",
        "# Preparing the API Request for Anthropic Claude\n",
        "native_request= {\n",
        "    \"anthropic_version\" : \"bedrock-2023-05-31\", # version of the anthropic claude\n",
        "    \"max_tokens\":25, # max new tokens that model has to generate\n",
        "    \"temperature\": 0.4, # a hyperparameter that regulates the creativity of text generation\n",
        "    \"messages\": [\n",
        "          {\"role\" : \"user\" , \"content\" : prompt}  #  The prompt is included as a \"user\" message\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f19b3c-2632-4b95-84fe-b62b5130ccea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:52.427463Z",
          "iopub.status.busy": "2025-02-24T21:09:52.427226Z",
          "iopub.status.idle": "2025-02-24T21:09:53.104026Z",
          "shell.execute_reply": "2025-02-24T21:09:53.103490Z",
          "shell.execute_reply.started": "2025-02-24T21:09:52.427444Z"
        },
        "id": "50f19b3c-2632-4b95-84fe-b62b5130ccea"
      },
      "outputs": [],
      "source": [
        "# convert the request into a json request; AWS Bedrock APIs require requests in JSON format, not Python dictionaries.\n",
        "request = json.dumps(native_request)\n",
        "# passing the json request and calling the model\n",
        "response= client.invoke_model(modelId=model_id,body=request)\n",
        "\n",
        "# the next two lines of code include parsing the model's response\n",
        "# Extracts the response body from AWS Bedrock.\n",
        "model_response= json.loads(response[\"body\"].read())\n",
        "prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\")\n",
        "# \"text\" is identified automatically by Claude. The explicit instruction \"Only predict whether it is Positive, or Negative.\" forces the model to output just one of these two labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00fdda0c-00c8-4f55-9599-aa303af2fa78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:53.104925Z",
          "iopub.status.busy": "2025-02-24T21:09:53.104671Z",
          "iopub.status.idle": "2025-02-24T21:09:53.108226Z",
          "shell.execute_reply": "2025-02-24T21:09:53.107712Z",
          "shell.execute_reply.started": "2025-02-24T21:09:53.104906Z"
        },
        "id": "00fdda0c-00c8-4f55-9599-aa303af2fa78",
        "outputId": "ba2ce050-e0d5-43b6-8806-5f133f899dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------Precicted sentiment (From LLM)-----------------------\n",
            "negative\n",
            "\n",
            "---------------Actual sentiment (From dataset)-----------------------\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "print(\"---------------Precicted sentiment (From LLM)-----------------------\")\n",
        "print(prediction)\n",
        "\n",
        "print(\"\\n---------------Actual sentiment (From dataset)-----------------------\")\n",
        "print(sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11031475-6e25-4f66-baae-259230aa351b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:53.110196Z",
          "iopub.status.busy": "2025-02-24T21:09:53.109957Z",
          "iopub.status.idle": "2025-02-24T21:09:53.115219Z",
          "shell.execute_reply": "2025-02-24T21:09:53.114695Z",
          "shell.execute_reply.started": "2025-02-24T21:09:53.110178Z"
        },
        "id": "11031475-6e25-4f66-baae-259230aa351b"
      },
      "outputs": [],
      "source": [
        "# Assuming `data_sample` is a DataFrame with 'review' and 'sentiment' columns\n",
        "\n",
        "from tqdm import tqdm  # tqdm is a popular Python library for creating progress bars in loops and long-running tasks.\n",
        "\n",
        "\n",
        "def predict_sentiment(test_set, model_id, client):\n",
        "    results = []\n",
        "    predictions=[]\n",
        "    actual=[]\n",
        "    for index, row in tqdm(test_set.iterrows()):\n",
        "        review = row['review']\n",
        "        actual_sentiment = row['sentiment']\n",
        "\n",
        "        prompt = f\"\"\" You are a highly accurate sentiment analysis model trained to classify movie reviews. Your task is to analyze the sentiment of the given review and categorize it as one of the following labels:\n",
        "\n",
        "positive: The review expresses a favorable opinion about the movie.\n",
        "negative: The review expresses an unfavorable opinion about the movie.\n",
        "\n",
        "Expected Output Format:\n",
        "positive/negative\n",
        "\n",
        "Provide only the sentiment label in one word without any additional explanation.\n",
        "                     {review}\n",
        "                 \"\"\"\n",
        "\n",
        "        native_request = {\n",
        "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "            \"max_tokens\": 20,\n",
        "            \"temperature\": 0.4,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        request = json.dumps(native_request)\n",
        "\n",
        "        response = client.invoke_model(modelId=model_id, body=request)\n",
        "\n",
        "        # Parse the response\n",
        "        model_response = json.loads(response[\"body\"].read())\n",
        "        prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip()\n",
        "\n",
        "\n",
        "\n",
        "        predictions.append(prediction.lower())\n",
        "        actual.append(actual_sentiment)\n",
        "\n",
        "    return predictions,actual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92bf5e29-9342-4f95-900d-bd40e7f1a998",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:53.116168Z",
          "iopub.status.busy": "2025-02-24T21:09:53.115863Z",
          "iopub.status.idle": "2025-02-24T21:09:53.127535Z",
          "shell.execute_reply": "2025-02-24T21:09:53.127066Z",
          "shell.execute_reply.started": "2025-02-24T21:09:53.116141Z"
        },
        "id": "92bf5e29-9342-4f95-900d-bd40e7f1a998",
        "outputId": "eccc046a-ab98-45d4-df77-d48ee3d1b67d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nicole Finn (Madonna) is just being released f...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is a pleasure to see such creativity on TV ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I really enjoyed watching this movie about the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An entertaining kung fu film, with acting, plo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This anime seriously rocked my socks. When the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>SEPARATE LIES is such an elegant, intelligent ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Tedious girls-at-reform-school flick, which pl...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>I have no idea as to which audience director G...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Kenneth Branagh's \"Hamlet\" hits all the marks....</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Please note that I haven't seen the film since...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                review sentiment\n",
              "0    Nicole Finn (Madonna) is just being released f...  positive\n",
              "1    It is a pleasure to see such creativity on TV ...  positive\n",
              "2    I really enjoyed watching this movie about the...  positive\n",
              "3    An entertaining kung fu film, with acting, plo...  positive\n",
              "4    This anime seriously rocked my socks. When the...  positive\n",
              "..                                                 ...       ...\n",
              "195  SEPARATE LIES is such an elegant, intelligent ...  positive\n",
              "196  Tedious girls-at-reform-school flick, which pl...  negative\n",
              "197  I have no idea as to which audience director G...  negative\n",
              "198  Kenneth Branagh's \"Hamlet\" hits all the marks....  positive\n",
              "199  Please note that I haven't seen the film since...  negative\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " # select 200 random data samples as part of the test set evaluation.\n",
        "random_indices = np.random.choice(data.index, size=200, replace=False)\n",
        "test_data = data.loc[random_indices].reset_index(drop=True)\n",
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aedab7ad-3dc8-4551-9487-61e63514bea8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:09:53.128354Z",
          "iopub.status.busy": "2025-02-24T21:09:53.128120Z",
          "iopub.status.idle": "2025-02-24T21:12:24.522901Z",
          "shell.execute_reply": "2025-02-24T21:12:24.522321Z",
          "shell.execute_reply.started": "2025-02-24T21:09:53.128337Z"
        },
        "id": "aedab7ad-3dc8-4551-9487-61e63514bea8",
        "outputId": "2dd28462-577a-419c-8215-b19832ecdc70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "200it [02:31,  1.32it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions,actual=predict_sentiment(test_data,model_id,client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c5d306-d208-4e40-9533-68cc6e93b0e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.524476Z",
          "iopub.status.busy": "2025-02-24T21:12:24.523569Z",
          "iopub.status.idle": "2025-02-24T21:12:24.536200Z",
          "shell.execute_reply": "2025-02-24T21:12:24.535722Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.524446Z"
        },
        "id": "d1c5d306-d208-4e40-9533-68cc6e93b0e5",
        "outputId": "3dd9cb4c-de0a-40d0-ea61-74ad6963f24c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.97      0.93      0.95       112\n",
            "    positive       0.91      0.97      0.94        88\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.94      0.95      0.94       200\n",
            "weighted avg       0.95      0.94      0.95       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(predictions,actual))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52fb9328-994b-463f-b72c-eccce56e20c5",
      "metadata": {
        "id": "52fb9328-994b-463f-b72c-eccce56e20c5"
      },
      "source": [
        "## Review\n",
        "\n",
        "We can observe that the model's response was accurate, LLMs handle the text very well considering the context and semantic relationships.\n",
        "\n",
        "Let's learn about a prompting technique using the same dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e08c59-2181-4060-b119-4c06d19583db",
      "metadata": {
        "id": "b6e08c59-2181-4060-b119-4c06d19583db"
      },
      "source": [
        "## Few-Shot Prompting\n",
        "\n",
        "Instead of relying solely on pre-trained knowledge (zero-shot prompting), few-shot prompting provides the model with a small number of labeled examples (typically 2â€“5) before asking it to complete the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d5b6e68-f934-476a-ad86-aadaecc841ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.540013Z",
          "iopub.status.busy": "2025-02-24T21:12:24.539834Z",
          "iopub.status.idle": "2025-02-24T21:12:24.544080Z",
          "shell.execute_reply": "2025-02-24T21:12:24.543577Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.539996Z"
        },
        "id": "5d5b6e68-f934-476a-ad86-aadaecc841ea"
      },
      "outputs": [],
      "source": [
        "# create n-examples\n",
        "# since we discussed that n-shot involves prompting the model with n examples. we need to create a function to randomly index n examples.\n",
        "def create_n_samples(data, n=3):\n",
        "    example_list=[] # a list to hold our n sample\n",
        "    for i in range(n):\n",
        "        random_index=random.randint(0,100) # create a random index\n",
        "        data_sample=data.iloc[random_index]\n",
        "        example_list.append(data_sample)\n",
        "    n_shot_examples=\"\"\n",
        "    for i in example_list:\n",
        "        n_shot_examples=n_shot_examples+'\\n'+\"Review: \"+i['review']+'\\n\\n'+\"Sentiment :\"+i['sentiment']+'\\n\\n'\n",
        "    # print(n_shot_examples)\n",
        "    return n_shot_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15a0734-db59-4224-84f4-42313a772310",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.545011Z",
          "iopub.status.busy": "2025-02-24T21:12:24.544805Z",
          "iopub.status.idle": "2025-02-24T21:12:24.548764Z",
          "shell.execute_reply": "2025-02-24T21:12:24.548311Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.544993Z"
        },
        "id": "f15a0734-db59-4224-84f4-42313a772310",
        "outputId": "d1ace96d-4329-4ac9-ae66-888450380508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Review: This a fantastic movie of three prisoners who become famous. One of the actors is george clooney and I'm not a fan but this roll is not bad. Another good thing about the movie is the soundtrack (The man of constant sorrow). I recommand this movie to everybody. Greetings Bart\n",
            "\n",
            "Sentiment :positive\n",
            "\n",
            "\n",
            "Review: Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n",
            "\n",
            "Sentiment :negative\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n = 2 # n value; do not use values >8 as it will flood the window of the model with unnecessary context.\n",
        "n_shot_prompt = create_n_samples(data , n)\n",
        "print(n_shot_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29c3bec-9ee2-462a-b642-5b526c0bbf05",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.549616Z",
          "iopub.status.busy": "2025-02-24T21:12:24.549358Z",
          "iopub.status.idle": "2025-02-24T21:12:24.554823Z",
          "shell.execute_reply": "2025-02-24T21:12:24.554329Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.549597Z"
        },
        "id": "d29c3bec-9ee2-462a-b642-5b526c0bbf05",
        "outputId": "e98314e4-6001-46e7-d936-d08963ddaa51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       Don't get me wrong , I want to see marijuana l...\n",
              "sentiment                                             negative\n",
              "Name: 48699, dtype: object"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_index=random.randint(101,50000) # create a random index\n",
        "data_sample=data.iloc[random_index] # access a random sample from the dataset using random_index\n",
        "data_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd78e511-56c7-4da4-9940-f924b820028a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.555655Z",
          "iopub.status.busy": "2025-02-24T21:12:24.555402Z",
          "iopub.status.idle": "2025-02-24T21:12:24.559744Z",
          "shell.execute_reply": "2025-02-24T21:12:24.559268Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.555635Z"
        },
        "id": "fd78e511-56c7-4da4-9940-f924b820028a",
        "outputId": "da06bc68-ea1f-4fac-9fd3-0b58d0591b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Classify the sentiment of the following movie reviews as positive or negative. Here are some examples:\n",
            "\n",
            "\n",
            "Review: This a fantastic movie of three prisoners who become famous. One of the actors is george clooney and I'm not a fan but this roll is not bad. Another good thing about the movie is the soundtrack (The man of constant sorrow). I recommand this movie to everybody. Greetings Bart\n",
            "\n",
            "Sentiment :positive\n",
            "\n",
            "\n",
            "Review: Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n",
            "\n",
            "Sentiment :negative\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "            predict the sentiment of the review given below as positive or negative in one word\n",
            "\n",
            "    \n",
            "            Don't get me wrong , I want to see marijuana legalized as much as the next guy. I shall digress now. The writing, though, was unrealistic. A PTA mom dealing drugs but adamant about her drugs getting into the hands of an underage person. Give me a break. The smugness of very pretty Mary Louise Parkers character was an insult to my intelligence. The characters were not at all likable. Basically, the plot lines went nowhere. I understand its only TV land . The hypocrisy was blatant. Mary Louise Parker is supposed to be a great mom and I am supposed to believe this.... WHY ???? I just got the feeling I was being preached by a show reeking of seediness. Its like saying its OK to cheat on your wife , but with someone of legal age status. OK not exactly the same thing , but I think you people get my point. That save the children stuff is wonderful for campaign trails , I guess, but it does not hold water in a cable sitcom about a suburbanite mom , as the local pot dealer.\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "# now prompt the model\n",
        "review=data_sample['review']\n",
        "sentiment=data_sample['sentiment']\n",
        "# crafting the prompt with the n examples\n",
        "prompt=f''' Classify the sentiment of the following movie reviews as positive or negative. Here are some examples:\\n\n",
        "{n_shot_prompt}\\n\\n\n",
        "            predict the sentiment of the review given below as positive or negative in one word\\n\\n\n",
        "            {review}\n",
        "        '''\n",
        "\n",
        "formatted_prompt = f\"Human: {prompt}\\n\\nAssistant:\"    # \"Assistant:\" signals to the model that it should now generate a response.\n",
        "\n",
        "native_request= {\n",
        "    \"anthropic_version\" : \"bedrock-2023-05-31\", # version of the  anthropic claude\n",
        "    \"max_tokens\":20, # max new tokens that model has to generate\n",
        "    \"temperature\": 0.1, # a hyperparameter that regulates the creativity of text generation\n",
        "    \"messages\": [\n",
        "          {\"role\" : \"user\" , \"content\" : formatted_prompt}\n",
        "    ]\n",
        "}\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2537ebb-46cb-4e1f-b196-bed0903d54be",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:24.560670Z",
          "iopub.status.busy": "2025-02-24T21:12:24.560365Z",
          "iopub.status.idle": "2025-02-24T21:12:25.131715Z",
          "shell.execute_reply": "2025-02-24T21:12:25.131131Z",
          "shell.execute_reply.started": "2025-02-24T21:12:24.560643Z"
        },
        "id": "e2537ebb-46cb-4e1f-b196-bed0903d54be",
        "outputId": "c32b83e9-52a5-4b92-fe9f-b86d6d13ac1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative\n"
          ]
        }
      ],
      "source": [
        "request = json.dumps(native_request)  # convert the request into a json request\n",
        "response= client.invoke_model(modelId=model_id,body=request) # passing the json request and calling the model\n",
        "# the next two lines of code include parsing the model's response\n",
        "model_response= json.loads(response[\"body\"].read())\n",
        "prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\")\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe80a5a-b479-4d96-804b-857d5f2a0845",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:25.132965Z",
          "iopub.status.busy": "2025-02-24T21:12:25.132454Z",
          "iopub.status.idle": "2025-02-24T21:12:25.136279Z",
          "shell.execute_reply": "2025-02-24T21:12:25.135703Z",
          "shell.execute_reply.started": "2025-02-24T21:12:25.132935Z"
        },
        "id": "bbe80a5a-b479-4d96-804b-857d5f2a0845",
        "outputId": "a80f72aa-5620-499d-fe30-8bc381e798be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------Precicted sentiment (From LLM)-----------------------\n",
            "negative\n",
            "\n",
            "---------------Actual sentiment (From dataset)-----------------------\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "print(\"---------------Precicted sentiment (From LLM)-----------------------\")\n",
        "print(prediction)\n",
        "print(\"\\n---------------Actual sentiment (From dataset)-----------------------\")\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0947d4d6-0837-4aae-899d-2fe18429a245",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:25.137194Z",
          "iopub.status.busy": "2025-02-24T21:12:25.136946Z",
          "iopub.status.idle": "2025-02-24T21:12:25.142816Z",
          "shell.execute_reply": "2025-02-24T21:12:25.142334Z",
          "shell.execute_reply.started": "2025-02-24T21:12:25.137175Z"
        },
        "id": "0947d4d6-0837-4aae-899d-2fe18429a245"
      },
      "outputs": [],
      "source": [
        "# Assuming `data_sample` is a DataFrame with 'review' and 'sentiment' columns\n",
        "from tqdm import tqdm\n",
        "def predict_sentiment(test_set,n_shot_prompt, model_id, client):\n",
        "    \"\"\"\n",
        "    Predicts sentiment (positive/negative) for a set of movie reviews using a few-shot prompting approach\n",
        "    with an LLM model accessed via AWS Bedrock.\n",
        "\n",
        "    Parameters:\n",
        "    - test_set: Pandas DataFrame containing movie reviews and their actual sentiments.\n",
        "    - n_shot_prompt: Few-shot prompt containing example sentiment classifications.\n",
        "    - model_id: Identifier for the LLM model (e.g., Anthropic Claude via AWS Bedrock).\n",
        "    - client: API client to interact with the model.\n",
        "\n",
        "    Returns:\n",
        "    - predictions: List of predicted sentiment labels from the model.\n",
        "    - actual: List of actual sentiment labels from the dataset.\n",
        "    \"\"\"\n",
        "    results = []  # List to store full response results (not currently used)\n",
        "    predictions = []  # List to store model-generated sentiment predictions\n",
        "    actual = []  # List to store actual sentiment labels from the dataset\n",
        "\n",
        "    # Iterate over each row in the test dataset with a progress bar\n",
        "    for index, row in tqdm(test_set.iterrows()):\n",
        "        review = row['review']  # Extract the movie review text\n",
        "        actual_sentiment = row['sentiment']  # Extract the actual sentiment label\n",
        "\n",
        "        # Construct the few-shot prompt with example classifications\n",
        "        prompt = f''' Classify the sentiment of the following movie reviews as positive or negative. Here are some examples:\\n\n",
        "        {n_shot_prompt}\\n\\n\n",
        "            Predict the sentiment of the review given below as positive or negative in one word:\\n\\n\n",
        "            {review}\n",
        "        '''\n",
        "\n",
        "        # Format the prompt according to Anthropic's expected chat format\n",
        "        formatted_prompt = f\"Human: {prompt}\\n\\nAssistant:\"\n",
        "\n",
        "        # Create the API request payload for AWS Bedrock\n",
        "        native_request = {\n",
        "            \"anthropic_version\": \"bedrock-2023-05-31\",  # Specify the version of the API\n",
        "            \"max_tokens\": 20,  # Limit response length to ensure only one-word predictions\n",
        "            \"temperature\": 0.4,  # Set temperature for less randomness and more consistent responses\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": formatted_prompt}  # Pass the formatted user prompt\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        request = json.dumps(native_request)  # Convert the request payload to JSON format\n",
        "\n",
        "        # Invoke the AWS Bedrock model with the request\n",
        "        response = client.invoke_model(modelId=model_id, body=request)\n",
        "\n",
        "        # Parse the response from the model\n",
        "        model_response = json.loads(response[\"body\"].read())  # Read and parse the response body\n",
        "\n",
        "        # Extract the sentiment prediction (handling possible response structure variations)\n",
        "        prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip()\n",
        "\n",
        "        # Store the lowercase version of the prediction for consistency\n",
        "        predictions.append(prediction.lower())\n",
        "\n",
        "        # Store the actual sentiment from the dataset for evaluation\n",
        "        actual.append(actual_sentiment)\n",
        "\n",
        "    # Return the list of predicted sentiments and actual sentiments for comparison\n",
        "    return predictions, actual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176e9ac3-32ca-4a6a-88b9-78771e731715",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:12:25.143662Z",
          "iopub.status.busy": "2025-02-24T21:12:25.143420Z",
          "iopub.status.idle": "2025-02-24T21:15:12.246096Z",
          "shell.execute_reply": "2025-02-24T21:15:12.245579Z",
          "shell.execute_reply.started": "2025-02-24T21:12:25.143644Z"
        },
        "id": "176e9ac3-32ca-4a6a-88b9-78771e731715",
        "outputId": "f9b43838-f720-4f96-f685-ad7cea6672e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "200it [02:47,  1.20it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions,actual=predict_sentiment( test_data, n_shot_prompt, model_id, client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4beaa2bd-b905-4222-91d9-dcdbcd6b50de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.247124Z",
          "iopub.status.busy": "2025-02-24T21:15:12.246842Z",
          "iopub.status.idle": "2025-02-24T21:15:12.257956Z",
          "shell.execute_reply": "2025-02-24T21:15:12.257461Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.247095Z"
        },
        "id": "4beaa2bd-b905-4222-91d9-dcdbcd6b50de",
        "outputId": "80f644aa-a983-4adb-c640-25924dea65df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.94      0.96      0.95       107\n",
            "    positive       0.96      0.92      0.94        93\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.95      0.94      0.94       200\n",
            "weighted avg       0.95      0.94      0.94       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(actual,predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2e8021-2427-4b79-96e0-f738ae17f08c",
      "metadata": {
        "id": "cb2e8021-2427-4b79-96e0-f738ae17f08c"
      },
      "source": [
        "## Using Multiple LLMs for Sentiment Analysis\n",
        "We have seen how we can craft the prompt to provide context & question. Sometimes we come across tasks which can't be solved using a single instance\n",
        "\n",
        "Here's a simple use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1976ce-eb82-46a8-bd5a-9c582fb93a18",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.262189Z",
          "iopub.status.busy": "2025-02-24T21:15:12.261953Z",
          "iopub.status.idle": "2025-02-24T21:15:12.264765Z",
          "shell.execute_reply": "2025-02-24T21:15:12.264276Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.262171Z"
        },
        "id": "4d1976ce-eb82-46a8-bd5a-9c582fb93a18"
      },
      "outputs": [],
      "source": [
        "model_id_1='anthropic.claude-3-sonnet-20240229-v1:0' # LLM1\n",
        "model_id_2='meta.llama3-70b-instruct-v1:0' # LLM2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c52203b-2d07-47bb-abd9-edc2f678d9d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.265610Z",
          "iopub.status.busy": "2025-02-24T21:15:12.265342Z",
          "iopub.status.idle": "2025-02-24T21:15:12.269707Z",
          "shell.execute_reply": "2025-02-24T21:15:12.269196Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.265587Z"
        },
        "id": "2c52203b-2d07-47bb-abd9-edc2f678d9d5",
        "outputId": "7f2c8bca-b6ca-4365-fb05-51c0b1b0e090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How powerful and captivating simple quality filmmaking can be. This film tells it's tale with everyday scenes that manage to revel the poignancy hidden within. It's true as others have stated, how this film really makes it glaringly obvious how lost Hollywood is in it's special effects, overblown emotionalism and over the top climatic endings and have forgotten the essence of a meaningful story told with simple realism. So much of what these characters are going through is implied by the scene rather than spelled out in wordy dialogue. One aspect that I really enjoyed about the film was the contrast of the two brothers, one so very openly expressive in his childlike way and the other completely stoic but both able to evoke deep emotion. The older brother needed to say little, as he usually did, it was all there in that deadpan face of his! Beautiful cinematography, wonderful acting, great direction! Not to be missed!\n",
            "positive\n"
          ]
        }
      ],
      "source": [
        "random_index=random.randint(101,50000) # create a random index\n",
        "data_sample=data.iloc[random_index] # access a random sample from the dataset using random_index\n",
        "print(data_sample['review'])\n",
        "print(data_sample['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ce90b1-2bb9-48e8-a02b-c25e0fb192c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.270552Z",
          "iopub.status.busy": "2025-02-24T21:15:12.270316Z",
          "iopub.status.idle": "2025-02-24T21:15:12.273915Z",
          "shell.execute_reply": "2025-02-24T21:15:12.273400Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.270534Z"
        },
        "id": "a4ce90b1-2bb9-48e8-a02b-c25e0fb192c6"
      },
      "outputs": [],
      "source": [
        "review=data_sample['review']\n",
        "sentiment=data_sample['sentiment']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc70a45-09f6-4c4b-a698-3a0f7c861f06",
      "metadata": {
        "id": "1fc70a45-09f6-4c4b-a698-3a0f7c861f06"
      },
      "source": [
        "### First LLM\n",
        "\n",
        "let's ask the first model to make a sentiment prediction given a review.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862dd609-1dc7-4c7f-9fa5-4034a0fe00cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.276995Z",
          "iopub.status.busy": "2025-02-24T21:15:12.276704Z",
          "iopub.status.idle": "2025-02-24T21:15:12.279839Z",
          "shell.execute_reply": "2025-02-24T21:15:12.279351Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.276979Z"
        },
        "id": "862dd609-1dc7-4c7f-9fa5-4034a0fe00cb"
      },
      "outputs": [],
      "source": [
        "prompt=f'''\n",
        "        Review: {review}\n",
        "\n",
        "        summarize the given review.\n",
        "\n",
        "        '''\n",
        "native_request = {\n",
        "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "        \"max_tokens\": 100,\n",
        "        \"temperature\": 0.5,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c18ba1-34d5-4d3c-975a-e5635c308679",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:12.280613Z",
          "iopub.status.busy": "2025-02-24T21:15:12.280397Z",
          "iopub.status.idle": "2025-02-24T21:15:17.698074Z",
          "shell.execute_reply": "2025-02-24T21:15:17.697450Z",
          "shell.execute_reply.started": "2025-02-24T21:15:12.280597Z"
        },
        "id": "c4c18ba1-34d5-4d3c-975a-e5635c308679",
        "outputId": "bfc88e89-4800-4441-ca28-97a01b5b8619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given review highly praises the film for its powerful and captivating storytelling through simple, quality filmmaking. It commends the film's ability to reveal poignancy in everyday scenes, contrasting it with Hollywood's overreliance on special effects, overblown emotionalism, and over-the-top climactic endings. The review appreciates the film's meaningful story told with simple realism, where much is implied through scenes rather than wordy dialogue. It highlights the\n"
          ]
        }
      ],
      "source": [
        "request = json.dumps(native_request)  # convert the request into a json request\n",
        "response= client.invoke_model(modelId=model_id_1,body=request) # passing the json request and calling the model\n",
        "# the next two lines of code include parsing the model's response\n",
        "model_response= json.loads(response[\"body\"].read())\n",
        "prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\")\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a46b891a-627e-44cd-8e97-1a74ff1dfdfd",
      "metadata": {
        "id": "a46b891a-627e-44cd-8e97-1a74ff1dfdfd"
      },
      "source": [
        "### Second LLM\n",
        "Let's pass the prediction made by the first LLM to the second LLM and ask it to breakdown the reason for the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8d3ce1-578d-4647-83ed-cee4e0cb8176",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:17.700981Z",
          "iopub.status.busy": "2025-02-24T21:15:17.700647Z",
          "iopub.status.idle": "2025-02-24T21:15:17.704179Z",
          "shell.execute_reply": "2025-02-24T21:15:17.703707Z",
          "shell.execute_reply.started": "2025-02-24T21:15:17.700953Z"
        },
        "id": "cb8d3ce1-578d-4647-83ed-cee4e0cb8176"
      },
      "outputs": [],
      "source": [
        "prompt=f'''\n",
        "        Summary : {prediction}\n",
        "        Now from the summary, list the things the reviewer likes and dislikes\n",
        "        '''\n",
        "\n",
        "# Note that, the syntax here for Llama differs from that of Claude\n",
        "formatted_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|> \"\"\"\n",
        "native_request = {\n",
        "    \"prompt\": formatted_prompt,\n",
        "    \"max_gen_len\": 512,\n",
        "    \"temperature\": 0.5,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c86239a-818e-425b-a24d-966a0bf89ebf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T21:15:17.705137Z",
          "iopub.status.busy": "2025-02-24T21:15:17.704860Z",
          "iopub.status.idle": "2025-02-24T21:15:19.871660Z",
          "shell.execute_reply": "2025-02-24T21:15:19.871065Z",
          "shell.execute_reply.started": "2025-02-24T21:15:17.705118Z"
        },
        "id": "9c86239a-818e-425b-a24d-966a0bf89ebf",
        "outputId": "e710c55b-1510-4c99-ff43-aaeb84f9f4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|end_header_id|><|start_header_id|><|end_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Based on the summary, here are the things the reviewer likes and dislikes:\n",
            "\n",
            "**Likes:**\n",
            "\n",
            "* Powerful and captivating storytelling\n",
            "* Simple, quality filmmaking\n",
            "* Ability to reveal poignancy in everyday scenes\n",
            "* Meaningful story told with simple realism\n",
            "* Implication of meaning through scenes rather than wordy dialogue\n",
            "\n",
            "**Dislikes:**\n",
            "\n",
            "* Hollywood's overreliance on special effects\n",
            "* Overblown emotionalism\n",
            "* Over-the-top climactic endings\n"
          ]
        }
      ],
      "source": [
        "request = json.dumps(native_request) # converting into json request\n",
        "response = client.invoke_model(modelId=model_id_2, body=request) # invoking the model\n",
        "# parsing the model's response\n",
        "model_response = json.loads(response[\"body\"].read())\n",
        "output = model_response.get(\"generation\", \"\")   # Note that, LLaMA (Meta) Response Formats here differs from that of Claude (Anthropic)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e930a356-508e-4384-947e-308a76e8dd08",
      "metadata": {
        "id": "e930a356-508e-4384-947e-308a76e8dd08"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}